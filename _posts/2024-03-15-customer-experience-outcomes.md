---
layout: post
title:  "Customer experience outcomes of focused, user-centered product design improvements"
authors:
  - apasun
date:   2024-03-15 0:00:10 -0700
categories:
  - community
excerpt: The OpenSearch Project invites the OpenSearch community to explore the future of search, analytics, and generative AI at the first OpenSearch user conference in Europe. Join us in Berlin on May 6 & 7 and learn how to build powerful applications and get the most out of your OpenSearch deployments.
meta_keywords: 
meta_description: 
---

## User experience challenges

A large proportion of software improvements focus on features and functionality. It is common practice for product managers and developers to incrementally add engineering capabilities. When the implementation of a seamless experience is not taken into account, the result can be a fragmented user experience. While these changes may not affect the perceived experience of a high-code user, low-code users report excess frustration and a lack of satisfaction with an experience when changes to software do not aid in accomplishing set outcomes that a software experience intends to deliver.

When navigating software, users utilize two types of memory: episodic and semantic. Episodic memory is grounded in the sequence of time, while semantic memory is conceptual. We, as humans, are capable of experiencing our online environment in both ways and often switch between the two types of memory as we navigate software. When functionality is enhanced incrementally, however, navigation that fails to account for the logical buildup of user tasks in a software workflow can quickly degrade the experience. Such product experiences end up ill designed and requiring ongoing customer support to help coach, train, and assist the user.

## Is there a way to measure user experience?
The [Customer Outcome Framework](https://productmanagementuniversity.com/launches-customer-outcome-framework/) employs a top-down view of the customer experience. Customer Experience Outcomes (CXOs) [define critical tasks that a product must perform and how well those tasks must be performed](https://lithespeed.com/drive-input-customer-experience-outcomes/#:~:text=What%20is%20a%20Customer%20Experience%20Outcome%20or,a%20plan%20for%20success:%20%E2%80%9CIf%20we%20do). A comprehensive set of CXO measures may include [quality and loyalty measures](https://www.forrester.com/research/cx-index/). Additional outcome measures may include [satisfaction and frustration scores](https://www.dynatrace.com/news/blog/user-experience-score-the-one-metric-to-rule-them-all/), [UMUX](https://testscience.org/measuring-usability/#UMUX)[measures](https://testscience.org/measuring-usability/#UMUX), [UMUX-lite measures](https://testscience.org/measuring-usability/#UMUX-LITE), or [SUS scores](https://testscience.org/measuring-usability/#SUS).

## OpenSearch experience outcomes
To measure OpenSearch CXOs, we first defined [distinct users](https://opensearch.org/blog/q1-survey-results/) based on roles and domain expertise. Once we validated these, we then parsed out pivotal nodes of each user’s experience as user flows. We intentionally limited the pivotal experience nodes to 3–6 in number so that we could manage the length of the survey. For each node, we asked users to provide ratings for four measures representing their perception of the experience. We adopted UMUX scale measures to quantify satisfaction, frustration, usefulness, and usability. After each set of ratings, we invited our users to tell us how we might improve. The survey was hosted for two quarters (Q3–Q4 2023), and we obtained 130 responses in total from OpenSearch Dashboards users.

![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_2.2.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_2.3.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_2.4.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/DataAdmin_Graph_3.2.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/DataAdmin_Graph_3.3.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Search_Producers_4.2.png){: .img-fluid width="30%"}
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Security_Analytics_6.2.png){: .img-fluid width="30%"}



## Findings and areas of improvement 

Of the rated experiences, the *Security Analytics Producer* experience was best rated overall (82.58%). The *Dashboards* *Consumer* (68.98%) and *Infra Admin* experiences (69.13%) indicated opportunities for improvement. The results of this survey indicated that *Infra User* experiences such as *Deployment* (63.95%) and *Migration* (69.53%) could be improved and that *Dashboards* *Consumer* experiences such as *Root Cause Analysis* (65.28%) and *Ad Hoc Analysis* (67.83%) could be improved.


While these findings will help us to improve known experiences, we are always looking for new opportunities to make improvements in our search and analytics user segments. Consider providing your feedback by completing the [2024 Search and Analytics Survey](https://www.research.net/r/JJGMP3R). This survey is hosted by Linux Foundation Research.


![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/InfraUser_Graph_2.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/DataAdmin_Graph_3.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Search_Producers_4.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Log_Analytics_5.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Security_Analytics_6.1.png){: .img-fluid }
![](/assets/media/blog-images/2024-03-15-customer-experience-outcomes/Analytics_Customer_7.1.png){: .img-fluid }

### References

- [https://lithespeed.com/drive-input-customer-experience-outcomes/](https://lithespeed.com/drive-input-customer-experience-outcomes/#:~:text=What%20is%20a%20Customer%20Experience%20Outcome%20or,a%20plan%20for%20success:%20%E2%80%9CIf%20we%20do)

- [https://productmanagementuniversity.com/launches-customer-outcome-framework/](https://productmanagementuniversity.com/launches-customer-outcome-framework/)

[https://www.forrester.com/research/cx-index/](https://www.forrester.com/research/cx-index/)

[https://testscience.org/measuring-usability/#UMUX](https://testscience.org/measuring-usability/#UMUX)

[https://testscience.org/measuring-usability/#UMUX-LITE](https://testscience.org/measuring-usability/#UMUX-LITE)

[https://testscience.org/measuring-usability/#SUS](https://testscience.org/measuring-usability/#SUS)

